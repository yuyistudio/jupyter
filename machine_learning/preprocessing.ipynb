{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "//anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二值化\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.4  0.5  0.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-94608404003a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbinarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# copy为False的时候，会直接操作输入的nparray（传入内置list仍然会进行copy）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mbinarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 大于threshold的都变成1，其他都变成0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mori\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mbinarize\u001b[0;34m(X, threshold, copy)\u001b[0m\n\u001b[1;32m   1558\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \"\"\"\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.4  0.5  0.6].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# 处理标签值\n",
    "\n",
    "print '二值化'\n",
    "\n",
    "binarizer = pp.Binarizer(threshold=0.5, copy=False) # copy为False的时候，会直接操作输入的nparray（传入内置list仍然会进行copy）\n",
    "ori = np.array([0.4,0.5,0.6])\n",
    "print binarizer.transform(ori) # 大于threshold的都变成1，其他都变成0\n",
    "print ori\n",
    "\n",
    "print '标签二进制化'\n",
    "print pp.label_binarize([11, 33, 99, 222, 123], classes=[11, 33, 99, 222]) # 这是一个函数，输入是： (目标分类，所有分类的列表)\n",
    "# 找不到的分类输出为全0\n",
    "\n",
    "print\n",
    "\n",
    "X = np.array([[11, 111, 'china'], [12, 122, 'japan'], [13, 133, 'russia'], [14, 144, 'china']])\n",
    "X0 = X[:,0:2]\n",
    "X1 = pp.label_binarize(X[:,2], classes=['china', 'japan']) # 这是一个函数，输入参数为： (目标分类，所有分类的列表)\n",
    "print np.hstack((X0, X1))\n",
    "\n",
    "print '不需要指定标签列表的标签二进制化'\n",
    "\n",
    "lb = pp.LabelBinarizer()\n",
    "lb.fit(X[:,2])\n",
    "print lb.classes_\n",
    "print lb.transform(X[:,2])\n",
    "\n",
    "print 'label值重新编号'\n",
    "\n",
    "le = pp.LabelEncoder() # 将所有label重新进行编号\n",
    "X = [11,22,33,'label1','label2'] # 重新编号为 0~4\n",
    "le.fit(X)\n",
    "print le.transform(X)\n",
    "\n",
    "print '多值标签的二进制化'\n",
    "\n",
    "mlb = pp.MultiLabelBinarizer()\n",
    "X = [('good','man','is','me'),('good','boy'),('bad','man'),('bad','boy')]\n",
    "\n",
    "mlb.fit(X) # 每个分类有若干个标签\n",
    "print mlb.classes_\n",
    "print 'multi:', mlb.transform(X)\n",
    "\n",
    "print '标签数值化'\n",
    "le = pp.LabelEncoder()\n",
    "print le.fit_transform(['good','bad','nice','very_good','so_so']) # 将类别标签编码为数字\n",
    "\n",
    "print '标签数值化 -> 数值二进制化'\n",
    "tags = ['good','bad','nice','very_good','so_so']\n",
    "tag_nums = pp.LabelEncoder().fit_transform(tags) # 将列表标签变为数值\n",
    "print pp.label_binarize(tag_nums, list(set(tag_nums))) # 将数值二进制化\n",
    "\n",
    "print '多标签同时处理，变为稀疏矩阵'\n",
    "# 多列label同时进行二进制化处理\n",
    "X = [[1,2],\n",
    "     [4,5],\n",
    "     [7,2]]\n",
    "ohe = pp.OneHotEncoder()\n",
    "ohe.fit(X)\n",
    "print ohe.transform(X) # 结果是一个稀疏矩阵（三元组表示法）\n",
    "\n",
    "'''\n",
    "[1,0,0, 1,0]\n",
    "[0,1,0, 0,1]\n",
    "[0,0,1, 1,0]\n",
    "稀疏矩阵表示法：\n",
    "(0,0) 1\n",
    "(0,3) 1\n",
    "(1,1) 1\n",
    "(1,4) 1\n",
    "(2,2) 1\n",
    "(2,3) 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4]\n",
      " [4 5 6]]\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "[[22  1  1 44]\n",
      " [55  1  1 11]\n",
      " [99  1  1 33]]\n"
     ]
    }
   ],
   "source": [
    "# 对每个值进行任意的转换\n",
    "\n",
    "ft = pp.FunctionTransformer(lambda x: x+1)\n",
    "print ft.fit_transform([[1,2,3],[3,4,5]]) # 对传入的元素每个调用指定的函数\n",
    "\n",
    "# 二值化\n",
    "\n",
    "x = np.array([\n",
    "        [22,22,33,44],\n",
    "        [55,33,22,11],\n",
    "        [99,44,33,33]])\n",
    "\n",
    "print pp.binarize(x[:,1:3], threshold=2.5, copy=False) # 将数值二分为 0 或者 1\n",
    "print x # 加上copy=False之后，直接修改了原始数据x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  3.]\n",
      " [ 2.  2.]\n",
      " [ 3.  4.]]\n",
      "[[ 1.  3.]\n",
      " [ 2.  2.]\n",
      " [ 3.  4.]]\n"
     ]
    }
   ],
   "source": [
    "# 补全缺失值\n",
    "\n",
    "i = pp.Imputer(missing_values='NaN', strategy='mean') # 补全缺失的值\n",
    "print i.fit_transform([[1,np.NaN], # 使用每一列的均值进行替换\n",
    "             [np.NaN,2],\n",
    "             [3,4]])\n",
    "i = pp.Imputer(missing_values=99, strategy='mean')\n",
    "print i.fit_transform([[1,99],\n",
    "             [99,2],\n",
    "             [3,4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel Centerer TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   1. ]\n",
      " [ 0.5  0.5]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准归一化\n",
      "[[-1.22474487  1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487 -1.22474487]]\n",
      "[ 0.  0.] [ 1.  1.]\n",
      "[ 0.  0.] [ 1.  1.]\n",
      "归一化向量长度\n",
      "[[ 0.9995503   0.02998651]\n",
      " [ 0.99995     0.0099995 ]\n",
      " [ 0.99999444  0.00333331]]\n",
      "按照最大最小值进行归一化\n",
      "[[ 1.   1. ]\n",
      " [ 0.5  0.5]\n",
      " [ 0.   0. ]]\n",
      "[[ 1.  -1. ]\n",
      " [ 0.5 -0.5]\n",
      " [ 0.   0. ]]\n",
      "能忍受极端值的归一化（鲁棒性较好的归一化），使用四分点?\n",
      "[[1, 2], [3, 4], [9, 14], [31, 41], [5, 42], [13, 34], [3, 14], [3, 4], [9, 14], [31, 41], [5, 42], [13, 34], [3, 14], [10011100, -10101100]]\n",
      "[[ -6.00000000e-01  -3.66412214e-01]\n",
      " [ -4.00000000e-01  -3.05343511e-01]\n",
      " [  2.00000000e-01   0.00000000e+00]\n",
      " [  2.40000000e+00   8.24427481e-01]\n",
      " [ -2.00000000e-01   8.54961832e-01]\n",
      " [  6.00000000e-01   6.10687023e-01]\n",
      " [ -4.00000000e-01   0.00000000e+00]\n",
      " [ -4.00000000e-01  -3.05343511e-01]\n",
      " [  2.00000000e-01   0.00000000e+00]\n",
      " [  2.40000000e+00   8.24427481e-01]\n",
      " [ -2.00000000e-01   8.54961832e-01]\n",
      " [  6.00000000e-01   6.10687023e-01]\n",
      " [ -4.00000000e-01   0.00000000e+00]\n",
      " [  1.00110930e+06  -3.08430962e+05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 归一化\n",
    "\n",
    "print '标准归一化'\n",
    "\n",
    "X = [[100,3],\n",
    "    [200,2],\n",
    "    [300,1]]\n",
    "X = np.array(X)\n",
    "sX = pp.scale(X) # 把每一列的重要性变得一样，scale到 [-1,1] \n",
    "print sX\n",
    "print sX.mean(axis=0), sX.std(axis=0) # scale之后 mean=0 var=1\n",
    "\n",
    "ss = pp.StandardScaler() # 跟上面的scale函数应该是同一个效果\n",
    "ss.fit(X)\n",
    "res = ss.transform(X)\n",
    "print res.mean(axis=0), res.std(axis=0)\n",
    "\n",
    "\n",
    "print '归一化向量长度'\n",
    "\n",
    "n = pp.Normalizer(norm='l2', copy=False) # l2应该是L2范数的意思.就是让每个列向量的长度变成1，方向不变（vector标准化）\n",
    "n.fit(X)\n",
    "print n.transform(X)\n",
    "\n",
    "print '按照最大最小值进行归一化'\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler() # 限制每一列的最大最小值。默认将输入列的最小最大值映射到 [0,1]\n",
    "print min_max_scaler.fit_transform([[2,300],\n",
    "                                   [1,150],\n",
    "                                   [0,0]])\n",
    "\n",
    "scaler = preprocessing.MaxAbsScaler() # 限制每一列的最大最小值。默认将输入列的最小最大值映射到 [-1,1]，0还是映射到0.\n",
    "print scaler.fit_transform([[2,-300],\n",
    "                           [1,-150],\n",
    "                           [0,0]])\n",
    "\n",
    "print '能忍受极端值的归一化（鲁棒性较好的归一化），使用四分点?' # TODO\n",
    "rs = pp.RobustScaler()\n",
    "x = [[1,2],\n",
    "    [3,4],\n",
    "    [9,14],\n",
    "    [31,41],\n",
    "    [5,42],\n",
    "    [13,34],\n",
    "    [3,14],\n",
    "    [3,4],\n",
    "    [9,14],\n",
    "    [31,41],\n",
    "    [5,42],\n",
    "    [13,34],\n",
    "    [3,14],\n",
    "    [10011100,-10101100]]\n",
    "rs.fit(x)\n",
    "print x\n",
    "print rs.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   1.   2.   1.   2.   4.]\n",
      " [  1.   3.   4.   9.  12.  16.]]\n",
      "[[  1.   1.   2.   1.   2.   4.]\n",
      " [  1.   3.   4.   9.  12.  16.]]\n"
     ]
    }
   ],
   "source": [
    "# 二项式展开？\n",
    "\n",
    "X = np.array([[1,2],[3,4]])\n",
    "pf = pp.PolynomialFeatures()\n",
    "pf.fit(X)\n",
    "print pf.transform(X)\n",
    "\n",
    "def test(X): # 进行将每一行进行了二项式展开？\n",
    "    res = []\n",
    "    for x in X:\n",
    "        res.append([1, x[0], x[1], x[0]**2, x[0]*x[1], x[1]**2])\n",
    "    return np.array(res, dtype='float64')\n",
    "print test(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  11.  22.]\n",
      " [  1.  33.  44.]]\n"
     ]
    }
   ],
   "source": [
    "# 在最左边添加一列1，实际上并没有什么卵用\n",
    "\n",
    "X = [[11,22],[33,44]]\n",
    "print pp.add_dummy_feature(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'boy' 'good' 'is' 'man' 'me']\n",
      "multi: [[0 0 0 0 0 0]] <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlb = pp.MultiLabelBinarizer()\n",
    "X = [('good','man','is','me'),('good','boy'),('bad','man'),('bad','boy')]\n",
    "\n",
    "mlb.fit(X) # 每个分类有若干个标签\n",
    "print mlb.classes_\n",
    "v = mlb.transform([[]])\n",
    "print 'multi:', v, type(v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
