{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/get_started/get_started\n",
    "\n",
    "import tensorflow as tf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1400001]\n",
      "12.94\n",
      "12.94\n",
      "[  5.   8.  11.  14.  17.]\n",
      "107.0\n",
      "[array([-0.99873865], dtype=float32), array([ 4.99713278], dtype=float32)]\n",
      "3.5387e-06\n"
     ]
    }
   ],
   "source": [
    "# tensor表示张量，一二三维张量 分别为 标量 向量 矩阵。更高维张量很少使用。\n",
    "# 张量可以是常量、变量（作为参数）、占位符（作为输入）\n",
    "n1 = tf.constant(3.14) # 一维张量\n",
    "# session用来执行一个函数或者优化器，作为Python和C++ Backend的中介。\n",
    "s = tf.Session()\n",
    "print s.run([n1])\n",
    "n2 = tf.constant(9.8)\n",
    "# 创建一个函数\n",
    "op1 = tf.add(n1, n2)\n",
    "print s.run(op1)\n",
    "\n",
    "p1 = tf.placeholder(tf.float32)\n",
    "p2 = tf.placeholder(tf.float32)\n",
    "p_add = p1 + p2\n",
    "print s.run(p_add, {p1: 3.14, p2: 9.8})\n",
    "\n",
    "W = tf.Variable([3.], dtype=tf.float32)\n",
    "b = tf.Variable([2.], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "lr = W * x + b\n",
    "init = tf.global_variables_initializer()\n",
    "s.run(init)\n",
    "print s.run(lr, {x: [1,2,3,4,5]})\n",
    "\n",
    "y = tf.placeholder(tf.float32)\n",
    "diff = tf.square(y - lr)\n",
    "loss = tf.reduce_sum(diff)\n",
    "data = [1,2,3]\n",
    "labels = [4,3,2]\n",
    "print s.run(loss, {x: data, y: labels})\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "for i in range(1000):\n",
    "    s.run(train, {x: data, y: labels})\n",
    "print s.run([W, b])\n",
    "print s.run(loss, {x: data, y: labels})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpkAknxd\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': '/var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpkAknxd', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpkAknxd/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 644.023\n",
      "INFO:tensorflow:loss = 0.220711, step = 101 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.084\n",
      "INFO:tensorflow:loss = 0.00646984, step = 201 (0.114 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 299 into /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpkAknxd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00111338.\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-29-08:16:12\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpkAknxd/model.ckpt-299\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-29-08:16:13\n",
      "INFO:tensorflow:Saving dict for global step 299: average_loss = 0.000621222, global_step = 299, loss = 0.00248489\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-29-08:16:14\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpkAknxd/model.ckpt-299\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-29-08:16:15\n",
      "INFO:tensorflow:Saving dict for global step 299: average_loss = 0.00703096, global_step = 299, loss = 0.0281238\n",
      "train metrics: {'average_loss': 0.00062122219, 'global_step': 299, 'loss': 0.0024848888}\n",
      "eval metrics: {'average_loss': 0.0070309616, 'global_step': 299, 'loss': 0.028123846}\n"
     ]
    }
   ],
   "source": [
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# linear classification, and many neural network classifiers and regressors.\n",
    "# The following code provides an estimator that does linear regression.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=299)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpHGxUwx\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': '/var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpHGxUwx', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpHGxUwx/model.ckpt.\n",
      "INFO:tensorflow:loss = 8.66328258808, step = 1\n",
      "INFO:tensorflow:global_step/sec: 932.837\n",
      "INFO:tensorflow:loss = 0.00656824125986, step = 101 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 898.174\n",
      "INFO:tensorflow:loss = 0.000355017149994, step = 201 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 927.609\n",
      "INFO:tensorflow:loss = 0.000379241032489, step = 301 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.411\n",
      "INFO:tensorflow:loss = 3.71038700157e-05, step = 401 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 975.819\n",
      "INFO:tensorflow:loss = 1.06113837487e-06, step = 501 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 986.027\n",
      "INFO:tensorflow:loss = 2.161421835e-07, step = 601 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 991.965\n",
      "INFO:tensorflow:loss = 2.74328295498e-08, step = 701 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 995.432\n",
      "INFO:tensorflow:loss = 7.78598383566e-10, step = 801 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 764.065\n",
      "INFO:tensorflow:loss = 1.22381398093e-10, step = 901 (0.132 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpHGxUwx/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.83566613261e-11.\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-01-07:52:51\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpHGxUwx/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-01-07:52:52\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.08298e-11\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-01-07:52:53\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/t4/8039y7kx1qxfwzdkd74ynx2m0000gn/T/tmpHGxUwx/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-01-07:52:54\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101007\n",
      "train metrics: {'loss': 1.0829803e-11, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100652, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W*features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # EstimatorSpec connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tutorial2\n",
    "# https://www.tensorflow.org/get_started/mnist/beginners\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "accuracy: 0.921\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A very simple MNIST classifier.\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/beginners\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def main():\n",
    "  # Import data\n",
    "  from tensorflow.examples.tutorials.mnist import input_data\n",
    "  mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "  # Create the model\n",
    "  x = tf.placeholder(tf.float32, [None, 784]) # Here None means that a dimension can be of any length.\n",
    "  W = tf.Variable(tf.zeros([784, 10]))\n",
    "  b = tf.Variable(tf.zeros([10]))\n",
    "  y = tf.matmul(x, W) + b\n",
    "\n",
    "  # Define loss and optimizer\n",
    "  y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "  # The raw formulation of cross-entropy,\n",
    "  #\n",
    "  #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n",
    "  #                                 reduction_indices=[1]))\n",
    "  #\n",
    "  # can be numerically unstable.\n",
    "  #\n",
    "  # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "  # outputs of 'y', and then average across the batch.\n",
    "  cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "  train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "  sess = tf.InteractiveSession()\n",
    "  tf.global_variables_initializer().run()\n",
    "  # Train\n",
    "  for _ in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "  # Test trained model\n",
    "  correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  print(\"accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y_: mnist.test.labels}))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "r = tf.argmax([[1,2,3],[4,3,2]], 1)\n",
    "s = tf.Session()\n",
    "s.run(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Tutorial3 https://www.tensorflow.org/get_started/mnist/pros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(3.140000104904175, dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guide: https://www.tensorflow.org/programmers_guide/tensors\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "s = tf.Session()\n",
    "exe = lambda v: print(s.run(v))\n",
    "t = tf.zeros([1,2,3,4,])  # tensor是immutable的\n",
    "    # PlaceHolder Variables Constant SparseTensor 都是 Tensor\n",
    "    # Tensor是一个计算单元，有input和output\n",
    "    # 多个tensor连接组成graph\n",
    "    # eval/run的过程就是计算graph的过程\n",
    "exe(tf.rank(t))  # 多少维的，例如矩阵是2维的\n",
    "exe(tf.shape(t))  # 每个维度的size\n",
    "\n",
    "t = tf.reshape(t, [6, 4])\n",
    "t.eval()  # 使用default session来run这个tensor. 返回一个 numpy array.\n",
    "\n",
    "# tensor的执行可能依赖context，例如 PlaceHolder\n",
    "p = tf.placeholder(tf.float32)\n",
    "p.eval(feed_dict={p:3.14})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.42\n",
      "9.42\n"
     ]
    }
   ],
   "source": [
    "# guide: https://www.tensorflow.org/programmers_guide/variables\n",
    "\n",
    "a = tf.Variable(3.14, tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "a = tf.Print(a, [a, b])  # 当eval a的时候，打印 a 和 b 的值。\n",
    "c = a + b\n",
    "s = tf.Session()\n",
    "\n",
    "s.run(tf.global_variables_initializer())  # 初始化session中涉及到的variables\n",
    "    # variable初始化的时候指定了初始值，估计是要在gpu或者其他地方用指定的初始值进行初始化操作\n",
    "print(s.run(c, feed_dict={b: 6.28}))\n",
    "\n",
    "tf.global_variables_initializer().run()  # 初始化default session\n",
    "print(c.eval(feed_dict={b: 6.28}))  # 貌似没有Print出来\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable my_var7 already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-84-9e1279d39543>\", line 1, in <module>\n    var = tf.get_variable(\"my_var7\", [2, 3], dtype=tf.float32, initializer=tf.zeros_initializer)\n  File \"//anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"//anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-9e1279d39543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_var7\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 创建指定名称的变量，维度为 2x3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 这个变量会一直存在。后续再创建同名变量会报错。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    662\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 664\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable my_var7 already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-84-9e1279d39543>\", line 1, in <module>\n    var = tf.get_variable(\"my_var7\", [2, 3], dtype=tf.float32, initializer=tf.zeros_initializer)\n  File \"//anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"//anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "var = tf.get_variable(\"my_var7\", [2, 3], dtype=tf.float32, initializer=tf.zeros_initializer)  \n",
    "    # 创建指定名称的变量，维度为 2x3. \n",
    "    # 这个变量会一直存在。后续再创建同名变量会报错。\n",
    "print(s.run(tf.report_uninitialized_variables()))\n",
    "tf.global_variables_initializer().run()\n",
    "var.eval()\n",
    "\n",
    "print(tf.GraphKeys.GLOBAL_VARIABLES)  # 设备间共享的变量\n",
    "print(tf.GraphKeys.TRAINABLE_VARIABLES)  # 可参与训练的变量\n",
    "print(tf.GraphKeys.LOCAL_VARIABLES)  # 不可参与训练的变量\n",
    "\n",
    "print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 自定义estimator: https://www.tensorflow.org/get_started/estimator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
